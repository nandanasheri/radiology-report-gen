{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124dc383",
   "metadata": {},
   "source": [
    "# Notebook to automate LLM Inference using LangChain\n",
    "Using Langchain as a framework to interact with Ollama models beyond the Terminal along with the possibility of setting up a pipeline to import an image, run Model inference and export the output to its corresponding study folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bc4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and functions required to convert images into base64 for the model inference\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c15478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert dcm files to png\n",
    "def dicom_to_png(dicom_path, png_path):\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    pixel_array = ds.pixel_array.astype(float)\n",
    "    scaled = (np.maximum(pixel_array, 0) / pixel_array.max()) * 255.0\n",
    "    img = Image.fromarray(scaled.astype(np.uint8)).convert(\"RGB\")\n",
    "    img.save(png_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb5e3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = './dataset'\n",
    "\n",
    "# this gives in each sub folder within dataset s0, s1, s2\n",
    "folders = sorted(os.listdir(data_dir))\n",
    "for folder in folders:\n",
    "   s_folder = os.path.join(data_dir, folder)\n",
    "   # gives all .dcm and .txt files within each study\n",
    "   all_files = os.listdir(s_folder)\n",
    "   dcm_files = [f for f in all_files if f.lower().endswith('.dcm')]\n",
    "   \n",
    "   for each_file in dcm_files:\n",
    "    path_to_save = os.path.join(s_folder, f\"{each_file[0:3]}.png\")\n",
    "    dicom_path = os.path.join(s_folder, each_file)\n",
    "    dicom_to_png(dicom_path, path_to_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c9d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Re-sized Base64 string\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"PNG\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2dba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0784ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which takes in data and converts into LangChain human message for the Model\n",
    "def prompt_func(data):\n",
    "    text = data[\"text\"]\n",
    "    image = data[\"image\"]\n",
    "\n",
    "    image_part = {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": f\"data:image/jpeg;base64,{image}\",\n",
    "    }\n",
    "\n",
    "    content_parts = []\n",
    "\n",
    "    text_part = {\"type\": \"text\", \"text\": text}\n",
    "\n",
    "    content_parts.append(image_part)\n",
    "    content_parts.append(text_part)\n",
    "\n",
    "    return [HumanMessage(content=content_parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d166f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "llm = ChatOllama(model=\"gemma3:4b-it-qat\", temperature=0)\n",
    "chain = prompt_func | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f0073c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "from PIL import Image\n",
    "\n",
    "# this gives in each sub folder within dataset s0, s1, s2\n",
    "folders = sorted(os.listdir(data_dir))\n",
    "\n",
    "for folder in folders:\n",
    "    s_folder = os.path.join(data_dir, folder)\n",
    "    # gives files within each study\n",
    "    all_files = os.listdir(s_folder)\n",
    "    image_files = [f for f in all_files if f.lower().endswith('.png')]\n",
    "\n",
    "    for each_file in image_files:\n",
    "        image_path = os.path.join(s_folder, each_file)\n",
    "        # file to write output into\n",
    "        model_output_path =  os.path.join(s_folder, f\"gemma-4b-{each_file[0:3]}.txt\")\n",
    "        img = Image.open(image_path)\n",
    "        # convert to base64 version of image\n",
    "        base64_str = convert_to_base64(img)\n",
    "        query_chain = chain.invoke(\n",
    "            {\"text\": \"You are a radiologist reviewing this imaging study. Based on the image provided, generate only the *Findings* section of a radiology report. Use structured, concise, and formal language consistent with professional radiology reporting. Do not include the Impression, Conclusion, or Recommendations.\", \n",
    "            \"image\": base64_str}\n",
    "            )\n",
    "        # write model output into a file\n",
    "        with open(model_output_path, \"w\") as file:\n",
    "            file.write(query_chain)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
